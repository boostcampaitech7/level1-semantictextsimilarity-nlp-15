path:
  train_path: data/train.csv # -> Train csv file path
  val_path: data/dev.csv
  dev_path: data/dev.csv
  predict_path: data/test.csv # -> Test csv file path

  checkpoint_path: checkpoint/ # -> Checkpoint save path
  output_path: output/ # -> Output csv save path
  submission_path: output/sample_submission.csv # -> Sample submission csv file path

# List of model names to use.
model:
#  model_name_1: beomi/KcELECTRA-base
  model_name_2: snunlp/KR-ELECTRA-discriminator
#  model_name_3: jhgan/ko-sroberta-multitask
#  #model_name_4: sentence-transformers/all-MiniLM-L6-v2
#  model_name_5: FacebookAI/xlm-roberta-large
#  model_name_6: monologg/koelectra-base-v3-discriminator
#  model_name_7: kakaobank/kf-deberta-base

#  model_name_8: intfloat/multilingual-e5-large-instruct
#  model_name_9: Jaume/gemma-2b-embeddings # 2 Billion Param Model, Very big
#  model_name_10: bespin-global-klue-sroberta-base-continue-learning-by-mnr

  ensemble_weight: [0.1, 0.15, 0.1, 0.45, 0.05, 0.05, 0.1]

hyperparameters:
  seed: 0
  num_labels: 1
  num_workers: 4
  batch_size: 16
  max_length: 128
  max_epoch: 1
  learning_rate: 1e-5
